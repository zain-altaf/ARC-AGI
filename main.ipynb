{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HISNipzMZZMy"
      },
      "source": [
        "# Implement a Convolutional Spiking Neural Network with Izhikevich neuron model and STDP/R-STDP\n",
        "\n",
        "#### This implementation references the following:\n",
        "\n",
        "(1) Eugene M. Izhikevich, \"Simple Model of Spiking Neurons,\" IEEE TNN, 2003\n",
        "\n",
        "(2) Mozafari et al., \"SpykeTorch: Efficient Simulation of CNNs With at Most One Spike per Neuron,\" Frontiers in Neuroscience, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyZtaappZZM1"
      },
      "source": [
        "# 1. Setting Up the Environment\n",
        "\n",
        "First we have to import all the necessary PyTorch and utility packages.\n",
        "\n",
        "These libraries will be used to build the convolutional SNN with Izhikevich neurons and STDP/R-STDP learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10qbytVMZZM1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynLwVkKEZZM2"
      },
      "source": [
        "# 2. Global Configuration Parameters\n",
        "\n",
        "We have to define the basic parameters for the simulation environment and the Izhikevich neuron model.\n",
        "\n",
        "Key parameters:\n",
        "- `TMAX`: Maximum number of time steps for spiking simulation\n",
        "- Izhikevich model parameters for \"Regular Spiking\" neurons:\n",
        "  - `a` : Time scale of recovery\n",
        "  - `b` : Sensitivity of recovery\n",
        "  - `c` : Post-spike reset value of membrane potential\n",
        "  - `d` : Post-spike reset of recovery\n",
        "\n",
        "These define the dynamics of the spiking neurons based on the Izhikevich 2003 paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBsGGwHnZZM3",
        "outputId": "1467deab-2525-408c-a735-a29998d10773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 1 executed: Imports done, device set to: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# This is the maximum number of time steps for the spiking simulation.\n",
        "TMAX = 15\n",
        "\n",
        "# The typical \"Regular Spiking (RS)\" is usually:\n",
        "a_ = 0.02\n",
        "b_ = 0.2\n",
        "c_ = -65.0\n",
        "d_ = 8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLlIytl8ZZM4"
      },
      "source": [
        "# 3. Converting Images to Spike Waves\n",
        "\n",
        "The `ToSpikeWave` transform needs to be implemented in order to convert standard image data into temporal spike patterns.\n",
        "\n",
        "- **Time-to-first-spike encoding**: Higher intensity pixels generate spikes earlier in the simulation\n",
        "- **Accumulative spike representation**: Once a neuron spikes at time t, it remains \"high\" (1) for all subsequent time steps\n",
        "- The output has shape [TMAX, channels, height, width] which represent the entire spike pattern over time\n",
        "\n",
        "This is essential for processing static images through a temporal spiking network, which allows the STDP learning mechanisms to be applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GirUQoG1ZZM5",
        "outputId": "68894663-541c-4b42-f797-e15d66f16db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 2 executed: Spike transform created.\n"
          ]
        }
      ],
      "source": [
        "class ToSpikeWave:\n",
        "    \"\"\"\n",
        "    Converts a 2D (or 3D) intensity image into an accumulative spike-wave\n",
        "    [TMAX, C, H, W].\n",
        "    \"\"\"\n",
        "    def __init__(self, Tmax=15):\n",
        "        self.Tmax = Tmax\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if img.max() > 1.0:\n",
        "            img = img / 255.0\n",
        "\n",
        "        spike_times = (1.0 - img) * (self.Tmax - 1)\n",
        "        spike_times = spike_times.clamp(0, self.Tmax - 1)\n",
        "\n",
        "        wave = torch.zeros((self.Tmax,) + img.shape, dtype=torch.float)\n",
        "        int_times = spike_times.mul(self.Tmax - 1).round().long()\n",
        "\n",
        "        C, H, W = img.shape\n",
        "        for c in range(C):\n",
        "            for r in range(H):\n",
        "                for w_ in range(W):\n",
        "                    st = int_times[c, r, w_].item()\n",
        "                    wave[st:, c, r, w_] = 1.0\n",
        "\n",
        "        return wave\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ToSpikeWave(Tmax=TMAX)\n",
        "])\n",
        "\n",
        "print(\"Spike transform created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldrR89fRZZM5"
      },
      "source": [
        "# 4. Izhikevich Neuron Model Implementation\n",
        "\n",
        "Now the Izhikevich neuron model will need to be implemented as a PyTorch module. It is a computationally efficient way to simulate biologically plausible neural dynamics.\n",
        "\n",
        "The key equations implemented are:\n",
        "- v' = 0.04v² + 5v + 140 - u + I\n",
        "- u' = a(bv - u)\n",
        "- If v ≥ 30mV, then v ← c, u ← u + d\n",
        "\n",
        "Where:\n",
        "- v is the membrane potential\n",
        "- u is the recovery variable\n",
        "- I is the input current\n",
        "\n",
        "This is a simplified version of the model but it can still reproduce various firing patterns which can be seen in biological neurons (regular spiking, bursting, etc.) by adjusting a few of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J0ynhVgZZM6",
        "outputId": "d4087a84-7748-4802-baa1-e380149e3cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 3 executed: IzhikevichLayer defined.\n"
          ]
        }
      ],
      "source": [
        "class IzhikevichLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Maintains a population of Izhikevich neurons.\n",
        "    Each forward pass -> single time-step update for all neurons.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_neurons, a=0.02, b=0.2, c=-65.0, d=8.0, init_v=-65.0):\n",
        "        super().__init__()\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.c = c\n",
        "        self.d = d\n",
        "        self.num_neurons = num_neurons\n",
        "\n",
        "        self.register_buffer('v', torch.full((num_neurons,), init_v))\n",
        "        self.register_buffer('u', self.b * self.v)\n",
        "\n",
        "    def forward(self, input_current):\n",
        "        dv = 0.04*self.v*self.v + 5*self.v + 140 - self.u + input_current\n",
        "        du = self.a * (self.b*self.v - self.u)\n",
        "\n",
        "        self.v = self.v + dv\n",
        "        self.u = self.u + du\n",
        "\n",
        "        spike_mask = (self.v >= 30.0)\n",
        "        self.v[spike_mask] = self.c\n",
        "        self.u[spike_mask] += self.d\n",
        "\n",
        "        return spike_mask.float(), self.v\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.v.fill_(self.c)\n",
        "        self.u.fill_(self.b * self.c)\n",
        "\n",
        "print(\"IzhikevichLayer defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hkn1mWfZZM7"
      },
      "source": [
        "# 5. Spiking Convolution and Pooling Operations\n",
        "\n",
        "Now, the core neural processing operations for the SNN needs to be implemented. We need to:\n",
        "\n",
        "1. **`SpikingConv2D`**: Apply the convolution to the spike wave across time steps\n",
        "   - This takes input spike wave [T, Fin, H, W] and produces potentials [T, Fout, H', W']\n",
        "   - It uses randomly initialized weights with mean=0.8, std=0.02\n",
        "\n",
        "2. **`spiking_fire`**: Convert potential values to spike waves\n",
        "   - This is when neurons fire when potential exceeds threshold\n",
        "   - Once a neuron fires, it stays \"on\" for all subsequent time steps\n",
        "\n",
        "3. **`spiking_pooling`**: Downsample spike waves using max-pooling\n",
        "   - This preserves temporal information while reducing spatial dimensions\n",
        "\n",
        "These form the building blocks of the convolutional SNN architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs4a5VNgZZM7",
        "outputId": "ae08af04-ae7c-4029-b170-98166e155f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 4 executed: SpikingConv2D, spiking_fire, spiking_pooling (with fix).\n"
          ]
        }
      ],
      "source": [
        "class SpikingConv2D(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution on accumulative spike-wave:\n",
        "    input shape [T, Fin, H, W] => output potentials [T, Fout, H_out, W_out]\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 weight_mean=0.8, weight_std=0.02):\n",
        "        super().__init__()\n",
        "        w = torch.normal(mean=weight_mean, std=weight_std,\n",
        "                         size=(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.weight = nn.Parameter(w)\n",
        "\n",
        "    def forward(self, spike_wave):\n",
        "        pot = F.conv2d(spike_wave, self.weight, bias=None,\n",
        "                       stride=1, padding=0)\n",
        "        return pot\n",
        "\n",
        "def spiking_fire(potentials, threshold):\n",
        "    \"\"\"\n",
        "    Convert potentials [T, F, H, W] to accumulative spike-wave [T, F, H, W].\n",
        "    Once a neuron crosses threshold at time t, it's 1 for all subsequent t'.\n",
        "    \"\"\"\n",
        "    T, C, H, W = potentials.shape\n",
        "    spike_wave = torch.zeros_like(potentials)\n",
        "    first_spike = torch.full((C, H, W), T, dtype=torch.long,\n",
        "                             device=potentials.device)\n",
        "\n",
        "    for t in range(T):\n",
        "        above_thresh = (potentials[t] >= threshold)\n",
        "        newly_spiked = above_thresh & (first_spike == T)\n",
        "        first_spike[newly_spiked] = t\n",
        "\n",
        "    for t in range(T):\n",
        "        spike_wave[t] = (first_spike <= t).float()\n",
        "    return spike_wave\n",
        "\n",
        "\n",
        "def spiking_pooling(spike_wave, kernel_size=2, stride=2):\n",
        "    \"\"\"\n",
        "    Basic 2D max-pooling on accumulative spike wave.\n",
        "    shape => [T, C, H, W] => [T, C, H_out, W_out]\n",
        "    \"\"\"\n",
        "    T, C, H, W = spike_wave.shape\n",
        "    reshaped = spike_wave.view(T*C, 1, H, W)\n",
        "    pooled = F.max_pool2d(reshaped, kernel_size, stride)\n",
        "    Hout = pooled.shape[2]\n",
        "    Wout = pooled.shape[3]\n",
        "    pooled = pooled.view(T, C, Hout, Wout)\n",
        "    return pooled\n",
        "\n",
        "print(\"SpikingConv2D, spiking_fire, spiking_pooling (with fix).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn5QBvz8ZZM7"
      },
      "source": [
        "# 6. STDP and Reward-Modulated STDP Learning Rules\n",
        "\n",
        "Now we have to implement the Spike-Timing-Dependent Plasticity (STDP) and its reward-modulated version (R-STDP).\n",
        "\n",
        "- **STDP**: Synaptic weights are updated based on the relative timing of pre- and post-synaptic spikes\n",
        "  - Pre-before-post timing strengthens connections (A_plus factor)\n",
        "  - Post-before-pre timing weakens connections (A_minus factor)\n",
        "  - Weight updates are bounded between lower bound (lb) and upper bound (ub)\n",
        "\n",
        "- **R-STDP**: Similar to STDP but modulated by a reward/punishment signal\n",
        "  - The reward factor scales the weight updates\n",
        "  - Positive reward reinforces the current pattern\n",
        "  - Negative reward weakens the current pattern\n",
        "\n",
        "These learning rules enable unsupervised (STDP) and reinforcement learning (R-STDP) in the spiking neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHwX9HxlZZM8",
        "outputId": "b140ffd6-c4b9-4e57-9542-c45328b62065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 5 executed: STDP and R-STDP update functions defined.\n"
          ]
        }
      ],
      "source": [
        "def stdp_update(\n",
        "    weight: torch.Tensor,\n",
        "    pre_spike_time: torch.Tensor,\n",
        "    post_spike_time: torch.Tensor,\n",
        "    A_plus: float,\n",
        "    A_minus: float,\n",
        "    lb: float,\n",
        "    ub: float\n",
        "):\n",
        "    # Convert post_spike_time to tensor if it's a float\n",
        "    if isinstance(post_spike_time, (int, float)):\n",
        "        post_spike_time = torch.tensor(post_spike_time, device=weight.device, dtype=torch.float)\n",
        "\n",
        "    # Handle the dimensionality correctly\n",
        "    if post_spike_time.dim() == 0:\n",
        "        # Create a simple condition based on comparing with pre_spike_time\n",
        "        cond = pre_spike_time <= post_spike_time\n",
        "    else:\n",
        "        # For non-scalar, reshape as needed\n",
        "        cond = pre_spike_time <= post_spike_time.reshape(-1, 1, 1)\n",
        "\n",
        "    factor = (weight - lb) * (ub - weight)\n",
        "\n",
        "    weight_update = torch.zeros_like(weight)\n",
        "    weight_update[cond] = A_plus * factor[cond]\n",
        "    weight_update[~cond] = A_minus * factor[~cond]\n",
        "\n",
        "    weight = weight + weight_update\n",
        "    weight = torch.clamp(weight, lb, ub)\n",
        "    return weight\n",
        "\n",
        "def r_stdp_update(\n",
        "    weight: torch.Tensor,\n",
        "    pre_spike_time: torch.Tensor,\n",
        "    post_spike_time: torch.Tensor,\n",
        "    A_plus: float,\n",
        "    A_minus: float,\n",
        "    lb: float,\n",
        "    ub: float,\n",
        "    reward: float\n",
        "):\n",
        "    # Convert post_spike_time to tensor if it's a float\n",
        "    if isinstance(post_spike_time, (int, float)):\n",
        "        post_spike_time = torch.tensor(post_spike_time, device=weight.device, dtype=torch.float)\n",
        "\n",
        "    # Handle the dimensionality correctly\n",
        "    if post_spike_time.dim() == 0:\n",
        "        # Create a simple condition based on comparing with pre_spike_time\n",
        "        cond = pre_spike_time <= post_spike_time\n",
        "    else:\n",
        "        # For non-scalar, reshape as needed\n",
        "        cond = pre_spike_time <= post_spike_time.reshape(-1, 1, 1)\n",
        "\n",
        "    factor = (weight - lb) * (ub - weight)\n",
        "\n",
        "    weight_update = torch.zeros_like(weight)\n",
        "    weight_update[cond] = reward * A_plus * factor[cond]\n",
        "    weight_update[~cond] = reward * A_minus * factor[~cond]\n",
        "\n",
        "    weight = weight + weight_update\n",
        "    weight = torch.clamp(weight, lb, ub)\n",
        "    return weight\n",
        "\n",
        "print(\"STDP and R-STDP update functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaDxdwdZZM8"
      },
      "source": [
        "# 7. Spike Processing and Winner Selection Functions\n",
        "\n",
        "Now we define a bunch of helper functions for processing spike data and implementing the winner-take-all mechanisms:\n",
        "\n",
        "1. **`first_spike_time_from_pot`**: Extracts the earliest time a potential crosses threshold\n",
        "   - Essential for determining when a neuron first spikes\n",
        "\n",
        "2. **`first_spike_time_from_wave`**: Extracts earliest spike times from a complete spike wave\n",
        "\n",
        "3. **`get_k_winners`**: Implements a competitive winner-take-all mechanism\n",
        "   - Selects k neurons with earliest spike times\n",
        "   - Uses peak potential as a tiebreaker\n",
        "   - Optional lateral inhibition with radius parameter\n",
        "   - Winners will be the neurons that get to update their weights via STDP\n",
        "\n",
        "These functions support the implementation of competitive learning and help process spike data for STDP updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9siKhfKZZM9",
        "outputId": "93e4100f-0508-4dda-b30a-b9cdd41c9b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 6 executed: Helper functions for spikes, winners, times.\n"
          ]
        }
      ],
      "source": [
        "def first_spike_time_from_pot(pot_t):\n",
        "    \"\"\"\n",
        "    pot_t shape [T], earliest time pot_t(t) >= 0 => t, else T\n",
        "    \"\"\"\n",
        "    thr = 0.0\n",
        "    idx = (pot_t >= thr).nonzero(as_tuple=True)[0]\n",
        "    if len(idx) == 0:\n",
        "        return pot_t.shape[0]\n",
        "    return float(idx[0].item())\n",
        "\n",
        "def first_spike_time_from_wave(spike_wave):\n",
        "    \"\"\"\n",
        "    spike_wave: [T, C, H, W], return earliest spike time => shape [C, H, W].\n",
        "    \"\"\"\n",
        "    T, C, H, W = spike_wave.shape\n",
        "    out = torch.full((C, H, W), T, dtype=torch.float, device=spike_wave.device)\n",
        "    for t in range(T):\n",
        "        mask = (spike_wave[t] >= 0.5)\n",
        "        out[mask] = torch.minimum(out[mask], torch.full_like(out[mask], float(t)))\n",
        "    return out\n",
        "\n",
        "def get_k_winners(pot, k=5, radius=2):\n",
        "    \"\"\"\n",
        "    pot [T, C, H, W], pick k neurons with earliest spike times.\n",
        "    If tie => use peak potential as tiebreak (like partial).\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot.shape\n",
        "    spike_times = torch.full((C, H, W), T, device=pot.device)\n",
        "    peak_pot = torch.zeros((C, H, W), device=pot.device)\n",
        "\n",
        "    for t in range(T):\n",
        "        slice_ = pot[t]\n",
        "        mask = (slice_ >= 0.0)\n",
        "        spike_times[mask] = torch.minimum(spike_times[mask], torch.full_like(spike_times[mask], float(t)))\n",
        "        peak_pot = torch.max(peak_pot, slice_)\n",
        "\n",
        "    st_flat = spike_times.view(-1)\n",
        "    pk_flat = peak_pot.view(-1)\n",
        "\n",
        "    coords = [(i // (H*W), (i % (H*W)) // W, (i % (H*W)) % W) for i in range(C*H*W)]\n",
        "    sorted_indices = sorted(range(C*H*W),\n",
        "                            key=lambda i: (st_flat[i].item(), -pk_flat[i].item()))\n",
        "    winners = []\n",
        "    used = torch.zeros((C, H, W), dtype=torch.bool)\n",
        "\n",
        "    for i in sorted_indices:\n",
        "        if len(winners) >= k:\n",
        "            break\n",
        "        f, r, c = coords[i]\n",
        "        if radius>0:\n",
        "            rr_min = max(0, r-radius)\n",
        "            rr_max = min(H, r+radius+1)\n",
        "            cc_min = max(0, c-radius)\n",
        "            cc_max = min(W, c+radius+1)\n",
        "            if used[f, rr_min:rr_max, cc_min:cc_max].any():\n",
        "                continue\n",
        "            else:\n",
        "                used[f, rr_min:rr_max, cc_min:cc_max] = True\n",
        "        winners.append((f, r, c))\n",
        "    return winners\n",
        "\n",
        "def get_better_winners(pot, k=5, radius=2, class_balance=True):\n",
        "    \"\"\"\n",
        "    Enhanced winner selection with better class balance\n",
        "    pot [T, C, H, W], pick k neurons with earliest spike times.\n",
        "    If class_balance=True, tries to select winners from different feature maps\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot.shape\n",
        "    spike_times = torch.full((C, H, W), T, device=pot.device)\n",
        "    peak_pot = torch.zeros((C, H, W), device=pot.device)\n",
        "\n",
        "    # Calculate spike times and peak potentials\n",
        "    for t in range(T):\n",
        "        slice_ = pot[t]\n",
        "        mask = (slice_ >= 0.0)\n",
        "        spike_times[mask] = torch.minimum(spike_times[mask], torch.full_like(spike_times[mask], float(t)))\n",
        "        peak_pot = torch.max(peak_pot, slice_)\n",
        "\n",
        "    st_flat = spike_times.view(-1)\n",
        "    pk_flat = peak_pot.view(-1)\n",
        "\n",
        "    # Create coordinates list for all potential neurons\n",
        "    coords = [(i // (H*W), (i % (H*W)) // W, (i % (H*W)) % W) for i in range(C*H*W)]\n",
        "\n",
        "    # Sort by spike time (primary) and peak potential (secondary)\n",
        "    sorted_indices = sorted(range(C*H*W),\n",
        "                           key=lambda i: (st_flat[i].item(), -pk_flat[i].item()))\n",
        "\n",
        "    winners = []\n",
        "    used = torch.zeros((C, H, W), dtype=torch.bool, device=pot.device)\n",
        "    class_count = torch.zeros(C, dtype=torch.int, device=pot.device)\n",
        "\n",
        "    max_per_class = k // 3 + 1 if class_balance else k  # Limit winners per class if balancing\n",
        "\n",
        "    for i in sorted_indices:\n",
        "        if len(winners) >= k:\n",
        "            break\n",
        "\n",
        "        f, r, c = coords[i]\n",
        "\n",
        "        # Skip if we've reached max count for this class and we want class balance\n",
        "        if class_balance and class_count[f] >= max_per_class:\n",
        "            continue\n",
        "\n",
        "        # Check for inhibition zone\n",
        "        if radius > 0:\n",
        "            rr_min = max(0, r-radius)\n",
        "            rr_max = min(H, r+radius+1)\n",
        "            cc_min = max(0, c-radius)\n",
        "            cc_max = min(W, c+radius+1)\n",
        "\n",
        "            if used[f, rr_min:rr_max, cc_min:cc_max].any():\n",
        "                continue\n",
        "            else:\n",
        "                used[f, rr_min:rr_max, cc_min:cc_max] = True\n",
        "\n",
        "        winners.append((f, r, c))\n",
        "        class_count[f] += 1\n",
        "\n",
        "    return winners\n",
        "\n",
        "print(\"Helper functions for spikes, winners, times.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u6eA2ZCZZM9"
      },
      "source": [
        "# 8. Deep Convolutional SNN Architecture\n",
        "\n",
        "Now we have to implement the complete three-layer Spiking CNN architecture with:\n",
        "\n",
        "1. **Layer Structure**:\n",
        "   - Layer 1: Convolutional layer + STDP learning\n",
        "   - Pooling\n",
        "   - Layer 2: Convolutional layer + STDP learning\n",
        "   - Pooling\n",
        "   - Layer 3: Output layer + R-STDP for classification\n",
        "\n",
        "2. **Learning Methods**:\n",
        "   - `forward_inference`: Regular forward pass for inference\n",
        "   - `forward_learn`: Forward pass with learning for a specific layer\n",
        "   - `apply_r_stdp`: Apply reward-modulated STDP\n",
        "   - `apply_r_stdp_direct`: Direct application of R-STDP to target neurons\n",
        "   - `stdp_update_layer`: Core function for updating weights with STDP\n",
        "\n",
        "This integrates all the previously defined components into a complete SNN architecture capable of unsupervised and reinforcement learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUQy-hX1ZZM9",
        "outputId": "b69ef89a-f0f0-4300-af4a-563433f5d249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 7 executed: DeepConvSNN created (with fix).\n"
          ]
        }
      ],
      "source": [
        "class DeepConvSNN(nn.Module):\n",
        "    \"\"\"\n",
        "    3-layer conv spiking net, approach from Mozafari et al. (2019).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=1,\n",
        "        layer1_channels=30, kernel1=5,\n",
        "        layer2_channels=100, kernel2=3,\n",
        "        layer3_channels=10, kernel3=5,\n",
        "        a=0.02, b=0.2, c=-65.0, d=8.0,\n",
        "        A_plus=0.004, A_minus=-0.003,\n",
        "        A_plus_r=0.004, A_minus_r=-0.003,\n",
        "        lb=0.0, ub=1.0,\n",
        "        reward_val=+1.0, punish_val=-1.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.conv1 = SpikingConv2D(in_channels, layer1_channels, kernel1)\n",
        "        self.conv2 = SpikingConv2D(layer1_channels, layer2_channels, kernel2)\n",
        "        self.conv3 = SpikingConv2D(layer2_channels, layer3_channels, kernel3)\n",
        "\n",
        "        self.A_plus = A_plus\n",
        "        self.A_minus = A_minus\n",
        "        self.A_plus_r = A_plus_r\n",
        "        self.A_minus_r = A_minus_r\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        self.reward_val = reward_val\n",
        "        self.punish_val = punish_val\n",
        "\n",
        "    def forward_inference(self, spike_wave):\n",
        "        pot1 = self.conv1(spike_wave)\n",
        "        spk1 = spiking_fire(pot1, 10.0)\n",
        "        spk1_pool = spiking_pooling(spk1, 2, 2)\n",
        "\n",
        "        pot2 = self.conv2(spk1_pool)\n",
        "        spk2 = spiking_fire(pot2, 5.0)\n",
        "        spk2_pool = spiking_pooling(spk2, 2, 2)\n",
        "\n",
        "        pot3 = self.conv3(spk2_pool)\n",
        "        return pot3\n",
        "\n",
        "    def forward_learn(self, spike_wave, layer_to_learn):\n",
        "        \"\"\"\n",
        "        Single sample => train a single layer with STDP or final layer with R-STDP.\n",
        "        \"\"\"\n",
        "        pot1 = self.conv1(spike_wave)\n",
        "        spk1 = spiking_fire(pot1, 5.0)\n",
        "        spk1_pool = spiking_pooling(spk1, 2, 2)\n",
        "\n",
        "        if layer_to_learn == 1:\n",
        "            winners = get_k_winners(pot1, 20, 2)\n",
        "            self.stdp_update_layer(self.conv1, spike_wave, pot1, winners, r_stdp=False)\n",
        "            return\n",
        "\n",
        "        pot2 = self.conv2(spk1_pool)\n",
        "        spk2 = spiking_fire(pot2, 3.0)\n",
        "        spk2_pool = spiking_pooling(spk2, 2, 2)\n",
        "\n",
        "        if layer_to_learn == 2:\n",
        "            winners = get_k_winners(pot2, 30, 1)\n",
        "            self.stdp_update_layer(self.conv2, spk1_pool, pot2, winners, r_stdp=False)\n",
        "            return\n",
        "\n",
        "        pot3 = self.conv3(spk2_pool)\n",
        "        return pot3\n",
        "\n",
        "    def apply_r_stdp(self, spike_wave, label, predicted):\n",
        "        pot3 = self.forward_inference(spike_wave)\n",
        "        winners = get_k_winners(pot3, k=1, radius=0)\n",
        "        rew = self.reward_val if (predicted == label) else self.punish_val\n",
        "        self.stdp_update_layer(self.conv3, None, pot3, winners, r_stdp=True, reward=rew)\n",
        "\n",
        "    def apply_r_stdp_direct(self, spike_wave, pot3, winners, reward):\n",
        "        \"\"\"Direct training of specific neurons with stronger reward\"\"\"\n",
        "        # Get the potentials from previous layers\n",
        "        pot1 = self.conv1(spike_wave)\n",
        "        spk1 = spiking_fire(pot1, 8.0)\n",
        "        spk1_pool = spiking_pooling(spk1, 2, 2)\n",
        "\n",
        "        pot2 = self.conv2(spk1_pool)\n",
        "        spk2 = spiking_fire(pot2, 6.0)\n",
        "        spk2_pool = spiking_pooling(spk2, 2, 2)\n",
        "\n",
        "        for (fout, rr, cc) in winners:\n",
        "            # Get pre-synaptic spike times for the specific kernel window\n",
        "            # Extract the correct kernel-sized window from spk2_pool based on the kernel size\n",
        "            kH, kW = self.conv3.weight.shape[2], self.conv3.weight.shape[3]  # Get actual kernel dimensions\n",
        "\n",
        "            # Make sure the window is properly sized\n",
        "            if rr + kH <= spk2_pool.shape[2] and cc + kW <= spk2_pool.shape[3]:\n",
        "                # Extract exactly the patch that would be used in convolution\n",
        "                pre_patch = spk2_pool[:, :, rr:rr+kH, cc:cc+kW]\n",
        "                T_pre = first_spike_time_from_wave(pre_patch)\n",
        "\n",
        "                # Use early spike time for the target neuron\n",
        "                T_post = 5.0 if reward > 0 else 10.0\n",
        "\n",
        "                # Apply stronger weight updates\n",
        "                self.conv3.weight.data[fout] = r_stdp_update(\n",
        "                    self.conv3.weight.data[fout],\n",
        "                    T_pre, T_post,\n",
        "                    self.A_plus_r*2, self.A_minus_r*2,\n",
        "                    self.lb, self.ub,\n",
        "                    reward\n",
        "                )\n",
        "\n",
        "\n",
        "    def stdp_update_layer(self, conv_layer, input_spike_wave, pot, winners, r_stdp=False, reward=0.0):\n",
        "        W = conv_layer.weight.data\n",
        "        kH = W.shape[2]\n",
        "        kW = W.shape[3]\n",
        "\n",
        "        for (fout, rr, cc) in winners:\n",
        "            T_post = first_spike_time_from_pot(pot[:, fout, rr, cc])\n",
        "            if input_spike_wave is not None:\n",
        "                pre_patch = input_spike_wave[:, :, rr:rr+kH, cc:cc+kW]\n",
        "                T_pre = first_spike_time_from_wave(pre_patch)\n",
        "            else:\n",
        "                T_pre = torch.zeros((W.shape[1], kH, kW), device=W.device)\n",
        "\n",
        "            if not r_stdp:\n",
        "                W[fout] = stdp_update(W[fout], T_pre, T_post,\n",
        "                                      self.A_plus, self.A_minus, self.lb, self.ub)\n",
        "            else:\n",
        "                W[fout] = r_stdp_update(W[fout], T_pre, T_post,\n",
        "                                        self.A_plus_r, self.A_minus_r, self.lb, self.ub, reward)\n",
        "        conv_layer.weight.data = W\n",
        "\n",
        "print(\"DeepConvSNN created (with fix).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bODm9MToZZM-"
      },
      "source": [
        "# 9. Training Pipeline and Utilities\n",
        "\n",
        "Now we set up the complete training pipeline for the SNN:\n",
        "\n",
        "1. **Data Loading**:\n",
        "   - MNIST dataset with our custom spike encoding transform\n",
        "   - Training and testing data loaders\n",
        "\n",
        "2. **Model Instantiation**:\n",
        "   - Creates the DeepConvSNN with specific parameters\n",
        "   - Configures learning rates, weight bounds, etc.\n",
        "\n",
        "3. **Training Functions**:\n",
        "   - `predict_class`: Infers the class from layer 3 potentials\n",
        "   - `train_layer`: Trains a specific layer with STDP\n",
        "   - `train_layer3_rstdp`: Trains the classification layer with R-STDP\n",
        "   - `test_accuracy`: Evaluates model performance\n",
        "   - `reset_model`: Reinitializes weights for fresh training\n",
        "   - `train_on_mistakes`: Focused training on misclassified examples\n",
        "\n",
        "These functions provide a complete pipeline for layerwise training and evaluation of the spiking neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ruJdoLmZZM_",
        "outputId": "9b44fe83-4f61-4fa2-e586-5e818380f450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 8 executed: Data loaded, model created, and training/testing functions defined.\n"
          ]
        }
      ],
      "source": [
        "# Datasets\n",
        "train_dataset = MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Instantiate net\n",
        "model = DeepConvSNN(\n",
        "    in_channels=1,\n",
        "    layer1_channels=30, kernel1=5,\n",
        "    layer2_channels=100, kernel2=3,\n",
        "    layer3_channels=10, kernel3=3,\n",
        "    a=a_, b=b_, c=c_, d=d_,\n",
        "    A_plus=0.01, A_minus=-0.008,\n",
        "    A_plus_r=0.01, A_minus_r=-0.008,\n",
        "    lb=0.2, ub=0.8,\n",
        "    reward_val=+1.0, punish_val=-1.0\n",
        ").to(device)\n",
        "\n",
        "\n",
        "def predict_class(pot3):\n",
        "    \"\"\"\n",
        "    Enhanced version - calculate spike count and timing together\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot3.shape\n",
        "    class_scores = torch.zeros(C, device=pot3.device)\n",
        "\n",
        "    for f in range(C):\n",
        "        # Maximum activation across spatial dimensions\n",
        "        channel_pot = pot3[:, f]\n",
        "        spike_mask = (channel_pot > 0).float()\n",
        "        spike_count = spike_mask.sum()\n",
        "\n",
        "        # Timing factor - earlier spikes are better\n",
        "        min_time = T\n",
        "        for t in range(T):\n",
        "            if spike_mask[t].sum() > 0:\n",
        "                min_time = t\n",
        "                break\n",
        "\n",
        "        # Combine factors - more spikes and earlier timing is better\n",
        "        class_scores[f] = spike_count * (T - min_time)\n",
        "\n",
        "    return torch.argmax(class_scores).item()\n",
        "\n",
        "\n",
        "def train_layer(model, loader, layer_idx, epochs=1, max_images=1000):\n",
        "    \"\"\"\n",
        "    Train a specific layer of the model\n",
        "    max_images: limit the number of training examples (set to None to use all)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            # Process the image\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            model.forward_learn(data_spike_wave.squeeze(0), layer_to_learn=layer_idx)\n",
        "\n",
        "            # Limit the number of training examples for faster testing\n",
        "            if max_images is not None and i >= max_images-1:\n",
        "                print(f\"Reached maximum images ({max_images}), stopping training\")\n",
        "                return\n",
        "\n",
        "def train_layer3_rstdp(model, loader, epochs=1, max_images=1000):\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        correct_during_training = 0\n",
        "        total_during_training = 0\n",
        "\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot3)\n",
        "            lbl = target.item()\n",
        "\n",
        "            # Apply stronger reward/punishment based on correctness\n",
        "            reward_val = 1.5 if pred_class_ == lbl else -1.5\n",
        "\n",
        "            # Force activation of the correct class neuron\n",
        "            winners = [(lbl, 0, 0)]  # Always update the weights for the correct class\n",
        "            model.apply_r_stdp_direct(data_spike_wave.squeeze(0), pot3, winners, reward_val)\n",
        "\n",
        "            # Track accuracy during training\n",
        "            if pred_class_ == lbl:\n",
        "                correct_during_training += 1\n",
        "            total_during_training += 1\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f\"Current training accuracy: {100*correct_during_training/total_during_training:.2f}%\")\n",
        "\n",
        "            if max_images is not None and i >= max_images-1:\n",
        "                print(f\"Reached maximum images ({max_images}), stopping training\")\n",
        "                return\n",
        "\n",
        "def train_layer3_rstdp_improved(model, loader, epochs=1, max_images=1000):\n",
        "    \"\"\"Enhanced R-STDP training for layer 3 with adaptive rewards\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    correct_during_training = 0\n",
        "    total_during_training = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        print(f\"Epoch {ep+1}/{epochs}\")\n",
        "\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot3)\n",
        "            lbl = target.item()\n",
        "\n",
        "            # Use the improved direct R-STDP method with both label and prediction\n",
        "            model.apply_r_stdp_direct_improved(\n",
        "                data_spike_wave.squeeze(0), pot3, lbl, pred_class_\n",
        "            )\n",
        "\n",
        "            # Track performance\n",
        "            if pred_class_ == lbl:\n",
        "                correct_during_training += 1\n",
        "            total_during_training += 1\n",
        "\n",
        "            # More frequent progress reporting\n",
        "            if i % 50 == 49:\n",
        "                current_acc = 100 * correct_during_training / total_during_training\n",
        "                print(f\"Current training accuracy: {current_acc:.2f}% [{i+1}/{max_images}]\")\n",
        "\n",
        "            # Stop if we've processed enough images\n",
        "            if max_images is not None and i >= max_images-1:\n",
        "                print(f\"Reached maximum images ({max_images}), stopping training\")\n",
        "                return\n",
        "\n",
        "        epoch_acc = 100 * correct_during_training / total_during_training\n",
        "        print(f\"Epoch {ep+1} completed. Training accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "def test_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot3)\n",
        "            if pred_class_ == target.item():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "def reset_model(model):\n",
        "    \"\"\"Reset model weights for a fresh training run\"\"\"\n",
        "    print(\"Resetting model weights for a new training attempt...\")\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, SpikingConv2D):\n",
        "            # Initialize with new random weights\n",
        "            w = torch.normal(mean=0.8, std=0.02, size=m.weight.shape)\n",
        "            m.weight.data = w\n",
        "    return model\n",
        "\n",
        "def train_on_mistakes(model, loader, max_mistakes=200):\n",
        "    print(\"Training specifically on misclassified examples...\")\n",
        "    mistakes_trained = 0\n",
        "    model.train()\n",
        "\n",
        "    for data_spike_wave, target in loader:\n",
        "        data_spike_wave = data_spike_wave.to(device)\n",
        "        pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "        pred = predict_class(pot3)\n",
        "\n",
        "        if pred != target.item():\n",
        "            lbl = target.item()\n",
        "            winners = [(lbl, 0, 0)]\n",
        "            reward_val = 2.0\n",
        "\n",
        "            model.apply_r_stdp_direct(data_spike_wave.squeeze(0), pot3, winners, reward_val)\n",
        "\n",
        "            mistakes_trained += 1\n",
        "            if mistakes_trained % 10 == 0:\n",
        "                print(f\"Trained on {mistakes_trained} mistakes...\")\n",
        "\n",
        "            if mistakes_trained >= max_mistakes:\n",
        "                print(f\"Reached maximum mistakes ({max_mistakes}), stopping training\")\n",
        "                break\n",
        "\n",
        "    return mistakes_trained\n",
        "\n",
        "print(\"Data loaded, model created, and training/testing functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbNQlkN5ZZM_"
      },
      "source": [
        "# 10. Model Training and Evaluation\n",
        "\n",
        "Now we execute the complete training procedure for the SNN:\n",
        "\n",
        "1. **Multi-attempt Training**:\n",
        "   - Tries multiple training runs with different weight initializations\n",
        "   - Keeps track of the best-performing model\n",
        "\n",
        "2. **Layer-wise Training Process**:\n",
        "   - Unsupervised STDP training for layer 1\n",
        "   - Unsupervised STDP training for layer 2\n",
        "   - Reward-modulated STDP training for layer 3\n",
        "\n",
        "3. **Performance Enhancement**:\n",
        "   - Focused training on misclassified examples\n",
        "   - Final accuracy evaluation\n",
        "\n",
        "The training process follows the approach from Mozafari et al. (2019), with additions to improve performance through multiple attempts and targeted training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHaPwsdVZZNA",
        "outputId": "ff3f7f72-8488-4e03-ae6a-65e6702a9247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Attempt 1 ===\n",
            "=== Unsupervised training layer 1 (Attempt 1) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 1 (Attempt 1)\n",
            "=== Unsupervised training layer 2 (Attempt 1) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 2 (Attempt 1)\n",
            "=== R-STDP training layer 3 (Attempt 1) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 9.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 8.50%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 9.00%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 10.50%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 10.20%\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 3 with R-STDP (Attempt 1)\n",
            "Training attempt 1 accuracy: 9.80%\n",
            "New best model found! Accuracy: 9.80%\n",
            "\n",
            "=== Training Attempt 2 ===\n",
            "Resetting model weights for a new training attempt...\n",
            "=== Unsupervised training layer 1 (Attempt 2) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 1 (Attempt 2)\n",
            "=== Unsupervised training layer 2 (Attempt 2) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 2 (Attempt 2)\n",
            "=== R-STDP training layer 3 (Attempt 2) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 8.50%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 8.00%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 7.50%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 8.60%\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 3 with R-STDP (Attempt 2)\n",
            "Training attempt 2 accuracy: 9.80%\n",
            "\n",
            "=== Training Attempt 3 ===\n",
            "Resetting model weights for a new training attempt...\n",
            "=== Unsupervised training layer 1 (Attempt 3) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 1 (Attempt 3)\n",
            "=== Unsupervised training layer 2 (Attempt 3) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 2 (Attempt 3)\n",
            "=== R-STDP training layer 3 (Attempt 3) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 9.50%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 9.33%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 10.20%\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 3 with R-STDP (Attempt 3)\n",
            "Training attempt 3 accuracy: 9.80%\n",
            "\n",
            "Best model accuracy: 9.80%\n",
            "Training specifically on misclassified examples...\n",
            "Trained on 10 mistakes...\n",
            "Trained on 20 mistakes...\n",
            "Trained on 30 mistakes...\n",
            "Trained on 40 mistakes...\n",
            "Trained on 50 mistakes...\n",
            "Trained on 60 mistakes...\n",
            "Trained on 70 mistakes...\n",
            "Trained on 80 mistakes...\n",
            "Trained on 90 mistakes...\n",
            "Trained on 100 mistakes...\n",
            "Reached maximum mistakes (100), stopping training\n",
            "Trained on 100 misclassified examples\n",
            "Final accuracy after mistake correction: 9.80%\n"
          ]
        }
      ],
      "source": [
        "# Run multiple training attempts to find the best model\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "for attempt in range(3):\n",
        "    print(f\"\\n=== Training Attempt {attempt+1} ===\")\n",
        "\n",
        "    # Reset model for new attempts\n",
        "    if attempt > 0:\n",
        "        model = reset_model(model)\n",
        "\n",
        "    # Train layer by layer\n",
        "    print(f\"=== Unsupervised training layer 1 (Attempt {attempt+1}) ===\")\n",
        "    train_layer(model, train_loader, layer_idx=1, epochs=2, max_images=500)\n",
        "    print(f\"Done training layer 1 (Attempt {attempt+1})\")\n",
        "\n",
        "    print(f\"=== Unsupervised training layer 2 (Attempt {attempt+1}) ===\")\n",
        "    train_layer(model, train_loader, layer_idx=2, epochs=2, max_images=500)\n",
        "    print(f\"Done training layer 2 (Attempt {attempt+1})\")\n",
        "\n",
        "    print(f\"=== R-STDP training layer 3 (Attempt {attempt+1}) ===\")\n",
        "    train_layer3_rstdp(model, train_loader, epochs=2, max_images=500)\n",
        "    print(f\"Done training layer 3 with R-STDP (Attempt {attempt+1})\")\n",
        "\n",
        "    # Test accuracy\n",
        "    acc = test_accuracy(model, test_loader)\n",
        "    print(f\"Training attempt {attempt+1} accuracy: {acc:.2f}%\")\n",
        "\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_model = copy.deepcopy(model)\n",
        "        print(f\"New best model found! Accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "# Use the best model for final results\n",
        "model = best_model\n",
        "print(f\"\\nBest model accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "# Apply focused training on mistakes to the best model\n",
        "mistakes_fixed = train_on_mistakes(model, train_loader, max_mistakes=100)\n",
        "print(f\"Trained on {mistakes_fixed} misclassified examples\")\n",
        "\n",
        "# Final accuracy check\n",
        "final_acc = test_accuracy(model, test_loader)\n",
        "print(f\"Final accuracy after mistake correction: {final_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Enabling Flexible DeepConvSNN for varying layers and neurons per layer"
      ],
      "metadata": {
        "id": "ylwY8pj5drrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleConvSNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Flexible-layer conv spiking net, based on Mozafari et al. (2019).\n",
        "    Allows varying number of layers and neurons per layer.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=1,\n",
        "        layer_configs=[(30, 5)],  # List of tuples: (num_channels, kernel_size)\n",
        "        num_classes=10,\n",
        "        neuron_params=None,\n",
        "        TMAX=15,\n",
        "    ):\n",
        "        super(FlexibleConvSNN, self).__init__()\n",
        "        self.TMAX = TMAX\n",
        "\n",
        "        if neuron_params is None:\n",
        "            neuron_params = {'a': 0.02, 'b': 0.2, 'c': -65.0, 'd': 8.0}\n",
        "\n",
        "        layers = []\n",
        "        last_channels = in_channels\n",
        "        for num_channels, kernel_size in layer_configs:\n",
        "            layers.append(\n",
        "                SpikingConv2D(\n",
        "                    in_channels=last_channels,\n",
        "                    out_channels=num_channels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1\n",
        "                )\n",
        "            )\n",
        "            layers.append(\n",
        "                IzhikevichLayer(num_neurons=num_channels, **neuron_params)\n",
        "            )\n",
        "            last_channels = num_channels\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        self.classifier = nn.Linear(last_channels, num_classes)\n",
        "\n",
        "    def forward(self, spike_wave):\n",
        "        x = spike_wave\n",
        "        for layer in self.features:\n",
        "            if isinstance(layer, SpikingConv2D):\n",
        "                x = layer(x)\n",
        "            elif isinstance(layer, IzhikevichLayer):\n",
        "                x = layer(x)\n",
        "\n",
        "        # Aggregate spikes over time dimension for classification\n",
        "        x = x.sum(dim=0)\n",
        "        x = F.avg_pool2d(x, x.size()[1:])  # Global average pooling\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ra2m_Mded-d-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}